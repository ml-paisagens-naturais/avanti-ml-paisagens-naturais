{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landscape Classification Pipeline Notebook\n",
    "# ===============================\n",
    "# \n",
    "# Este notebook serve como ponto de entrada para o pipeline completo de classificação de imagens de paisagens naturais.\n",
    "# O pipeline utiliza várias arquiteturas de deep learning (ResNet50, EfficientNet, Vision Transformer, MobileNet)\n",
    "# e integra diversos componentes como otimização de hiperparâmetros, ensemble de modelos e visualizações.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar exibição de gráficos no notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Verificar disponibilidade de GPU\n",
    "print(f\"PyTorch versão: {torch.__version__}\")\n",
    "print(f\"CUDA disponível: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Dispositivo atual: {device}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memória GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Dispositivo atual: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Configuração do ambiente\n",
    "\n",
    "# %%\n",
    "# Verificar e criar diretórios necessários\n",
    "def ensure_directories():\n",
    "    \"\"\"Verifica e cria os diretórios necessários para o pipeline.\"\"\"\n",
    "    directories = [\n",
    "        \"data\",\n",
    "        \"models\",\n",
    "        \"logs\",\n",
    "        \"results\",\n",
    "        \"tensorboard_logs\",\n",
    "        \"config\"\n",
    "    ]\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"✓ Diretório '{directory}' verificado/criado\")\n",
    "\n",
    "ensure_directories()\n",
    "\n",
    "# %%\n",
    "# Verificar se o arquivo de configuração existe, caso contrário criar um padrão\n",
    "CONFIG_PATH = 'config/config.yaml'\n",
    "\n",
    "if not os.path.exists(CONFIG_PATH):\n",
    "    print(\"Arquivo de configuração não encontrado. Criando configuração padrão...\")\n",
    "    \n",
    "    default_config = {\n",
    "        'dataset': {\n",
    "            'path': 'C:\\\\Dataset\\\\intel-image-classification',\n",
    "            'img_size': 224,\n",
    "            'batch_size': 32\n",
    "        },\n",
    "        'training': {\n",
    "            'epochs': 15,\n",
    "            'learning_rate': 0.001,\n",
    "            'gamma': 0.1,\n",
    "            'step_size': 7,\n",
    "            'seed': 42,\n",
    "            'k_folds': 5\n",
    "        },\n",
    "        'models': {\n",
    "            'use_resnet': True,\n",
    "            'use_efficientnet': True,\n",
    "            'use_mobilenet': True,\n",
    "            'use_vit': True\n",
    "        },\n",
    "        'flow_control': {\n",
    "            'run_data_exploration': True,\n",
    "            'run_dataset_prep': True,\n",
    "            'run_cross_validation': False,\n",
    "            'run_optimization': False,\n",
    "            'run_training': True,\n",
    "            'run_evaluation': True,\n",
    "            'run_visualization': True,\n",
    "            'run_compression': False,\n",
    "            'run_ensemble': True,\n",
    "            'run_export': False,\n",
    "            'run_final_report': True,\n",
    "            'run_duplicate_detection': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)\n",
    "    with open(CONFIG_PATH, 'w') as f:\n",
    "        yaml.dump(default_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Configuração padrão criada em {CONFIG_PATH}\")\n",
    "else:\n",
    "    print(f\"Arquivo de configuração encontrado em {CONFIG_PATH}\")\n",
    "\n",
    "# Carregar configuração\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"\\nConfiguração atual:\")\n",
    "print(json.dumps(config, indent=2))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Verificação de dependências\n",
    "\n",
    "# %%\n",
    "# Verificar a presença dos módulos auxiliares necessários\n",
    "required_modules = [\n",
    "    'utils',\n",
    "    'data_processing',\n",
    "    'dataset',\n",
    "    'dataset_utils',\n",
    "    'models',\n",
    "    'training',\n",
    "    'visualization',\n",
    "    'optimization',\n",
    "    'model_compression',\n",
    "    'ensemble',\n",
    "    'landscape_enhancements'\n",
    "]\n",
    "\n",
    "missing_modules = []\n",
    "for module_name in required_modules:\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        print(f\"✓ Módulo '{module_name}' carregado com sucesso\")\n",
    "    except ImportError:\n",
    "        missing_modules.append(module_name)\n",
    "        print(f\"✗ Módulo '{module_name}' não encontrado\")\n",
    "\n",
    "if missing_modules:\n",
    "    print(\"\\nAtenção: Os seguintes módulos estão faltando:\")\n",
    "    for module in missing_modules:\n",
    "        print(f\"  - {module}.py\")\n",
    "    print(\"\\nCertifique-se de que todos os arquivos .py auxiliares estão no mesmo diretório que este notebook.\")\n",
    "else:\n",
    "    print(\"\\nTodos os módulos necessários estão disponíveis.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Preparação do Dataset\n",
    "\n",
    "# %%\n",
    "# Verificar a presença dos dados ou fornecer instruções para download\n",
    "dataset_path = config['dataset']['path']\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Dataset não encontrado em '{dataset_path}'\")\n",
    "    print(\"\\nInstruções para download:\")\n",
    "    print(\"1. Faça o download do dataset 'Intel Image Classification' do Kaggle:\")\n",
    "    print(\"   https://www.kaggle.com/datasets/puneet6060/intel-image-classification\")\n",
    "    print(\"2. Extraia o arquivo baixado para o diretório 'data/intel-image-classification'\")\n",
    "    print(\"3. Execute esta célula novamente para verificar\")\n",
    "else:\n",
    "    # Verificar a estrutura do dataset\n",
    "    train_dir = os.path.join(dataset_path, 'seg_train', 'seg_train')\n",
    "    test_dir = os.path.join(dataset_path, 'seg_test', 'seg_test')\n",
    "    \n",
    "    # Verificar caminhos alternativos se os padrões não forem encontrados\n",
    "    if not os.path.exists(train_dir):\n",
    "        train_dir = os.path.join(dataset_path, 'train')\n",
    "    \n",
    "    if not os.path.exists(test_dir):\n",
    "        test_dir = os.path.join(dataset_path, 'test')\n",
    "    \n",
    "    train_exists = os.path.exists(train_dir)\n",
    "    test_exists = os.path.exists(test_dir)\n",
    "    \n",
    "    if train_exists and test_exists:\n",
    "        print(f\"✓ Dataset encontrado e estrutura validada\")\n",
    "        print(f\"  - Diretório de treinamento: {train_dir}\")\n",
    "        print(f\"  - Diretório de teste: {test_dir}\")\n",
    "        \n",
    "        # Mostrar um preview do dataset\n",
    "        import data_processing\n",
    "        \n",
    "        # Criar DataFrames com informações sobre as imagens\n",
    "        df_train, train_corrupted = data_processing.create_df(train_dir)\n",
    "        df_test, test_corrupted = data_processing.create_df(test_dir)\n",
    "        \n",
    "        print(f\"\\nEstatísticas do Dataset:\")\n",
    "        print(f\"  - Total de imagens de treinamento: {len(df_train)}\")\n",
    "        print(f\"  - Total de imagens de teste: {len(df_test)}\")\n",
    "        \n",
    "        if train_corrupted:\n",
    "            print(f\"  - Imagens corrompidas no treinamento: {len(train_corrupted)}\")\n",
    "        if test_corrupted:\n",
    "            print(f\"  - Imagens corrompidas no teste: {len(test_corrupted)}\")\n",
    "        \n",
    "        # Exibir a distribuição de classes\n",
    "        train_class_dist = df_train['label'].value_counts()\n",
    "        print(\"\\nDistribuição de classes (Treinamento):\")\n",
    "        print(train_class_dist)\n",
    "        \n",
    "        # Visualizar a distribuição\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=train_class_dist.index, y=train_class_dist.values)\n",
    "        plt.title(\"Distribuição de Classes - Conjunto de Treinamento\")\n",
    "        plt.ylabel(\"Número de imagens\")\n",
    "        plt.xlabel(\"Classe\")\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, v in enumerate(train_class_dist.values):\n",
    "            ax.text(i, v + 10, str(v), ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Exibir algumas imagens de exemplo\n",
    "        data_processing.show_random_images(df_train, num_images=9, save_path=None)\n",
    "    else:\n",
    "        print(f\"✗ Estrutura do dataset inválida\")\n",
    "        if not train_exists:\n",
    "            print(f\"  - Diretório de treinamento não encontrado: {train_dir}\")\n",
    "        if not test_exists:\n",
    "            print(f\"  - Diretório de teste não encontrado: {test_dir}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Executar o Pipeline Completo\n",
    "\n",
    "# %%\n",
    "# Atualizar configurações antes de executar o pipeline\n",
    "# Você pode modificar os parâmetros de configuração aqui conforme necessário\n",
    "\n",
    "# Exemplo de atualização de configuração\n",
    "config['training']['epochs'] = 10  # Reduzir o número de épocas para testes rápidos\n",
    "config['dataset']['batch_size'] = 16  # Reduzir batch size para economizar memória\n",
    "\n",
    "# Atualizar flags de controle do fluxo\n",
    "config['flow_control']['run_cross_validation'] = False  # Desabilitar validação cruzada\n",
    "config['flow_control']['run_optimization'] = False  # Desabilitar otimização de hiperparâmetros\n",
    "config['flow_control']['run_compression'] = False  # Desabilitar compressão de modelos\n",
    "\n",
    "# Adicionar nova flag para detecção de duplicatas\n",
    "if 'run_duplicate_detection' not in config['flow_control']:\n",
    "    config['flow_control']['run_duplicate_detection'] = True  # Habilitar detecção de duplicatas\n",
    "\n",
    "# Para executar apenas a detecção de duplicatas, desabilite as outras etapas\n",
    "# Descomente estas linhas se quiser executar apenas a detecção de duplicatas\n",
    "# config['flow_control']['run_dataset_prep'] = False\n",
    "# config['flow_control']['run_training'] = False\n",
    "# config['flow_control']['run_evaluation'] = False\n",
    "# config['flow_control']['run_visualization'] = False\n",
    "# config['flow_control']['run_ensemble'] = False\n",
    "# config['flow_control']['run_final_report'] = False\n",
    "\n",
    "# Salvar a configuração atualizada\n",
    "with open(CONFIG_PATH, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Configuração atualizada e salva.\")\n",
    "\n",
    "# %%\n",
    "# Configurar variáveis de ambiente e importar o main.py\n",
    "\n",
    "# Importar o módulo main contendo a função principal\n",
    "import main\n",
    "\n",
    "# Executar o pipeline principal\n",
    "print(\"Iniciando o pipeline de classificação de paisagens...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Executar o pipeline completo\n",
    "    main.main()\n",
    "    print(\"\\n✓ Pipeline executado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Erro durante a execução do pipeline: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.1 Visualização de Resultados da Detecção de Duplicatas\n",
    "\n",
    "# %%\n",
    "# Verificar e exibir resultados da detecção de duplicatas\n",
    "duplicates_report_path = \"results/duplicate_images.csv\"\n",
    "duplicates_viz_path = \"results/duplicates\"\n",
    "\n",
    "if os.path.exists(duplicates_report_path):\n",
    "    # Carregar o relatório de duplicatas\n",
    "    duplicates_df = pd.read_csv(duplicates_report_path)\n",
    "    \n",
    "    print(f\"Resultados da Detecção de Duplicatas:\")\n",
    "    print(f\"- Total de imagens duplicadas detectadas: {len(duplicates_df)}\")\n",
    "    print(f\"- Número de grupos de duplicatas: {duplicates_df['hash'].nunique()}\")\n",
    "    \n",
    "    # Mostrar a distribuição de tamanhos dos grupos\n",
    "    group_sizes = duplicates_df.groupby('hash').size().value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(group_sizes.index, group_sizes.values)\n",
    "    plt.title(\"Distribuição de Tamanhos de Grupos de Imagens Similares\")\n",
    "    plt.xlabel(\"Tamanho do grupo\")\n",
    "    plt.ylabel(\"Número de grupos\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Adicionar rótulos nas barras\n",
    "    for bar, size in zip(bars, group_sizes.values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, str(size), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Exibir exemplos de imagens duplicadas se disponíveis\n",
    "    duplicate_images = [f for f in os.listdir(duplicates_viz_path) if f.startswith('duplicate_group_') and f.endswith('.png')] if os.path.exists(duplicates_viz_path) else []\n",
    "    \n",
    "    if duplicate_images:\n",
    "        from IPython.display import Image, display\n",
    "        \n",
    "        print(\"\\nExemplos de grupos de imagens duplicadas/similares:\")\n",
    "        for img_path in sorted(duplicate_images)[:3]:  # Mostrar até 3 exemplos\n",
    "            display(Image(filename=os.path.join(duplicates_viz_path, img_path)))\n",
    "    \n",
    "else:\n",
    "    print(\"Relatório de detecção de duplicatas não encontrado. Execute o pipeline com a opção de detecção de duplicatas habilitada.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Análise de Resultados\n",
    "\n",
    "# %%\n",
    "# Carregar e visualizar os resultados após a execução\n",
    "results_path = \"results/evaluation_results.json\"\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as f:\n",
    "        evaluation_results = json.load(f)\n",
    "    \n",
    "    print(\"Resumo dos resultados:\")\n",
    "    model_accuracies = {}\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        accuracy = results['accuracy']\n",
    "        model_accuracies[model_name] = accuracy\n",
    "        print(f\"{model_name}: Acurácia = {accuracy:.4f}\")\n",
    "    \n",
    "    # Visualizar comparação de acurácias\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    models = list(model_accuracies.keys())\n",
    "    accuracies = [model_accuracies[name] for name in models]\n",
    "    \n",
    "    bars = plt.bar(models, accuracies, color='skyblue')\n",
    "    plt.title('Comparação de Acurácia entre Modelos', fontsize=14)\n",
    "    plt.ylabel('Acurácia', fontsize=12)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                 f'{height:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Verificar se resultados do ensemble estão disponíveis\n",
    "    ensemble_path = \"results/ensemble_comparison.png\"\n",
    "    if os.path.exists(ensemble_path):\n",
    "        from IPython.display import Image\n",
    "        print(\"\\nResultados do Ensemble:\")\n",
    "        display(Image(filename=ensemble_path))\n",
    "    \n",
    "    # Verificar se há visualizações Grad-CAM geradas\n",
    "    gradcam_dirs = [d for d in os.listdir('results') if d.startswith('gradcam_')]\n",
    "    if gradcam_dirs:\n",
    "        print(\"\\nVisualizações Grad-CAM disponíveis para os seguintes modelos:\")\n",
    "        for d in gradcam_dirs:\n",
    "            print(f\"- {d.replace('gradcam_', '')}\")\n",
    "        \n",
    "        # Mostrar exemplo para o primeiro modelo\n",
    "        sample_gradcam = os.path.join('results', gradcam_dirs[0], f'gradcam_summary_{gradcam_dirs[0].replace(\"gradcam_\", \"\")}.png')\n",
    "        if os.path.exists(sample_gradcam):\n",
    "            print(\"\\nExemplo de visualização Grad-CAM:\")\n",
    "            display(Image(filename=sample_gradcam))\n",
    "else:\n",
    "    print(\"Resultados de avaliação não encontrados. Execute o pipeline primeiro.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Funções Auxiliares para Análise Adicional\n",
    "\n",
    "# %%\n",
    "def load_model(model_name):\n",
    "    \"\"\"\n",
    "    Carrega um modelo treinado com base no nome.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Nome do modelo a ser carregado ('resnet50', 'efficientnet', 'vit', 'mobilenet')\n",
    "    \n",
    "    Returns:\n",
    "        model: Modelo PyTorch carregado\n",
    "    \"\"\"\n",
    "    import models\n",
    "    import torch\n",
    "    \n",
    "    # Carregar hiperparâmetros salvos\n",
    "    try:\n",
    "        with open('results/best_hyperparameters.json', 'r') as f:\n",
    "            params_data = json.load(f)\n",
    "        \n",
    "        model_params = params_data.get(model_name, {}).get('params', {})\n",
    "        \n",
    "        if model_name == 'resnet50':\n",
    "            model = models.create_model_with_best_params(model_params, model_name='resnet50')\n",
    "            model.load_state_dict(torch.load(f'models/{model_name}_final.pth'))\n",
    "        elif model_name == 'efficientnet':\n",
    "            model = models.create_model_with_best_params(model_params, model_name='efficientnet')\n",
    "            model.load_state_dict(torch.load(f'models/{model_name}_final.pth'))\n",
    "        elif model_name == 'vit':\n",
    "            vit_params = {\n",
    "                'model_name': model_params.get('model_type', 'vit_base_patch16_224'),\n",
    "                'pretrained': True,\n",
    "                'dropout_rate': model_params.get('dropout_rate', 0.1)\n",
    "            }\n",
    "            model = models.create_vit_model(vit_params)\n",
    "            model.load_state_dict(torch.load(f'models/{model_name}_final.pth'))\n",
    "        elif model_name == 'mobilenet':\n",
    "            # Determinar o número de classes a partir do conjunto de dados\n",
    "            import data_processing\n",
    "            train_dir = os.path.join(config['dataset']['path'], 'seg_train', 'seg_train')\n",
    "            if not os.path.exists(train_dir):\n",
    "                train_dir = os.path.join(config['dataset']['path'], 'train')\n",
    "            df_train, _ = data_processing.create_df(train_dir)\n",
    "            num_classes = len(df_train['label'].unique())\n",
    "            \n",
    "            model = models.mobilenet_v3_small(weights=None, num_classes=num_classes)\n",
    "            model.load_state_dict(torch.load(f'models/{model_name}_final.pth'))\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo não reconhecido: {model_name}\")\n",
    "        \n",
    "        model.eval()\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o modelo {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_single_image(image_path, model_name):\n",
    "    \"\"\"\n",
    "    Faz a predição para uma única imagem.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Caminho para a imagem\n",
    "        model_name (str): Nome do modelo a ser usado ('resnet50', 'efficientnet', 'vit', 'mobilenet')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (classe_predita, probabilidades)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "    import torchvision.transforms as transforms\n",
    "    \n",
    "    # Carregar o modelo\n",
    "    model = load_model(model_name)\n",
    "    if model is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Determinar as classes\n",
    "    import data_processing\n",
    "    train_dir = os.path.join(config['dataset']['path'], 'seg_train', 'seg_train')\n",
    "    if not os.path.exists(train_dir):\n",
    "        train_dir = os.path.join(config['dataset']['path'], 'train')\n",
    "    df_train, _ = data_processing.create_df(train_dir)\n",
    "    classes = sorted(df_train['label'].unique())\n",
    "    \n",
    "    # Preparar transformações\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Carregar e transformar a imagem\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "    \n",
    "    # Fazer a predição\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)[0].cpu().numpy()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = classes[predicted.item()]\n",
    "    \n",
    "    return predicted_class, probabilities\n",
    "\n",
    "# Função para visualizar predições\n",
    "def visualize_prediction(image_path, model_names=None):\n",
    "    \"\"\"\n",
    "    Visualiza a predição de vários modelos para uma única imagem.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Caminho para a imagem\n",
    "        model_names (list): Lista de nomes de modelos. Se None, usa todos os modelos disponíveis.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if model_names is None:\n",
    "        model_names = ['resnet50', 'efficientnet', 'vit', 'mobilenet']\n",
    "    \n",
    "    # Carregar a imagem\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Determinar as classes\n",
    "    import data_processing\n",
    "    train_dir = os.path.join(config['dataset']['path'], 'seg_train', 'seg_train')\n",
    "    if not os.path.exists(train_dir):\n",
    "        train_dir = os.path.join(config['dataset']['path'], 'train')\n",
    "    df_train, _ = data_processing.create_df(train_dir)\n",
    "    classes = sorted(df_train['label'].unique())\n",
    "    \n",
    "    # Configurar o gráfico\n",
    "    n_models = len(model_names)\n",
    "    fig, axs = plt.subplots(1, n_models + 1, figsize=(5 * (n_models + 1), 5))\n",
    "    \n",
    "    # Mostrar a imagem original\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(\"Imagem Original\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Para cada modelo, mostrar as probabilidades de classe\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        predicted_class, probabilities = predict_single_image(image_path, model_name)\n",
    "        \n",
    "        if predicted_class is not None and probabilities is not None:\n",
    "            # Mostrar gráfico de barras das probabilidades\n",
    "            bars = axs[i+1].bar(classes, probabilities)\n",
    "            axs[i+1].set_title(f\"{model_name}\\nPredição: {predicted_class}\")\n",
    "            axs[i+1].set_ylim(0, 1)\n",
    "            axs[i+1].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Destacar a classe predita\n",
    "            idx = classes.index(predicted_class)\n",
    "            bars[idx].set_color('red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %%\n",
    "# Exemplo de uso das funções auxiliares\n",
    "# Para usar, descomente e substitua pelo caminho real da imagem\n",
    "# image_path = \"caminho/para/sua/imagem.jpg\"\n",
    "# visualize_prediction(image_path)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Conclusão\n",
    "\n",
    "# %%\n",
    "# Carregar e exibir o resumo do experimento \n",
    "summary_files = [f for f in os.listdir('results') if f.startswith('experiment_summary_') and f.endswith('.txt')]\n",
    "\n",
    "if summary_files:\n",
    "    # Ordenar por data (assumindo o formato YYYYMMDD_HHMMSS no nome do arquivo)\n",
    "    latest_summary = sorted(summary_files)[-1]\n",
    "    \n",
    "    print(f\"Resumo do experimento mais recente ({latest_summary}):\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    with open(os.path.join('results', latest_summary), 'r') as f:\n",
    "        print(f.read())\n",
    "    \n",
    "    # Exibir visualização de resumo se disponível\n",
    "    summary_image = latest_summary.replace('.txt', '.png')\n",
    "    if os.path.exists(os.path.join('results', summary_image)):\n",
    "        from IPython.display import Image\n",
    "        print(\"\\nVisualização do resumo:\")\n",
    "        display(Image(filename=os.path.join('results', summary_image)))\n",
    "else:\n",
    "    print(\"Não foram encontrados resumos de experimentos. Execute o pipeline completo primeiro.\")\n",
    "\n",
    "# %%\n",
    "# Resumo do notebook e próximos passos\n",
    "print(\"Resumo do Pipeline de Classificação de Paisagens Naturais\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nEste notebook integrou o pipeline completo que inclui:\")\n",
    "print(\"1. Preparação e exploração do dataset\")\n",
    "print(\"2. Treinamento de múltiplos modelos (ResNet50, EfficientNet, Vision Transformer, MobileNet)\")\n",
    "print(\"3. Avaliação e visualização de resultados\")\n",
    "print(\"4. Técnicas avançadas como ensemble de modelos e interpretabilidade visual\")\n",
    "print(\"\\nPróximos passos possíveis:\")\n",
    "print(\"- Experimente com diferentes hiperparâmetros\")\n",
    "print(\"- Adicione novas arquiteturas de modelos\")\n",
    "print(\"- Aplique técnicas de data augmentation mais avançadas\")\n",
    "print(\"- Implemente quantização e pruning para modelos mais leves\")\n",
    "print(\"- Aplique o modelo a novas imagens de paisagens\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
